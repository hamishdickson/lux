env_args:
    env: 'lux'

train_args:
    turn_based_training: True
    observation: False
    gamma: 0.8
    forward_steps: 16
    compress_steps: 4
    entropy_regularization: 1.0e-1
    entropy_regularization_decay: 0.1
    update_episodes: 20
    batch_size: 32
    minimum_episodes: 1
    maximum_episodes: 1000
    epochs: -1
    num_batchers: 2
    eval_rate: 0.1
    worker:
        num_parallel: 6
    lambda: 0.7
    policy_target: 'VTRACE' # 'UPGO' 'VTRACE' 'TD' 'MC'
    value_target: 'VTRACE' # 'VTRACE' 'TD' 'MC'
    eval:
        opponent: ['random']
    seed: 0
    restart_epoch: 0